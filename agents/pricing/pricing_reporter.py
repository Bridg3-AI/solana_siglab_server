"""
Pricing Reporter (STEP 4)

ê°€ê²©ì±…ì • ê²°ê³¼ë¥¼ ë¦¬í¬íŒ…í•˜ê³  ê°ì‚¬ ì¶”ì ì„ ê´€ë¦¬í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.
"""

import json
import uuid
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import pandas as pd
import numpy as np

from .models.base import (
    PerilCanvas, FrequencyPrior, SeverityPrior, PricingResult, 
    AuditTrail, ScenarioData
)


class PricingReporter:
    """ê°€ê²©ì±…ì • ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±ê¸°"""
    
    def __init__(self):
        pass
    
    def generate_pricing_table(self, results: List[PricingResult]) -> pd.DataFrame:
        """
        í‘œì¤€í™”ëœ ê°€ê²©ì±…ì • í…Œì´ë¸” ìƒì„± (STEP 4 í‘œ í˜•ì‹)
        
        Args:
            results: PricingResult ê°ì²´ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ê°€ê²©ì±…ì • í…Œì´ë¸” DataFrame
        """
        
        table_data = []
        
        for result in results:
            # modify_plan.mdì˜ í‘œ í˜•ì‹ì— ë§ì¶° êµ¬ì„±
            row = {
                "Peril": result.peril,
                "EL (USD)": f"${result.expected_loss:,.0f}",
                "CoV": f"{result.coefficient_of_variation:.2f}",
                "Risk Load": f"{result.risk_load:.3f}",
                "Net Premium (USD)": f"${result.net_premium:,.0f}",
                "Gross Premium (USD)": f"${result.gross_premium:,.0f}",
                "VaR 99% (USD)": f"${result.var_99:,.0f}",
                "TVaR 99% (USD)": f"${result.tvar_99:,.0f}",
                "Risk Level": result.risk_level.value,
                "Recommendation": result.recommendation,
                "PML Ratio": f"{result.get_pml_ratio():.1f}x",
                "Tail Ratio": f"{result.get_tail_ratio():.2f}",
                "Simulation Years": result.simulation_years,
                "Timestamp": result.timestamp
            }
            
            table_data.append(row)
        
        return pd.DataFrame(table_data)
    
    def generate_sanity_dashboard(self, result: PricingResult) -> Dict[str, any]:
        """
        EL/VaR/TVaR ë¹„ìœ¨ ì²´í¬ë¥¼ ìœ„í•œ Sanity Dashboard
        
        Args:
            result: PricingResult ê°ì²´
            
        Returns:
            ëŒ€ì‹œë³´ë“œ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        
        dashboard = {
            "basic_metrics": {
                "expected_loss": result.expected_loss,
                "gross_premium": result.gross_premium,
                "premium_to_el_ratio": result.gross_premium / result.expected_loss if result.expected_loss > 0 else 0
            },
            "risk_metrics": {
                "var_99": result.var_99,
                "tvar_99": result.tvar_99,
                "pml_ratio": result.get_pml_ratio(),
                "tail_ratio": result.get_tail_ratio()
            },
            "validation_checks": self.validate_sanity_checks(result),
            "risk_assessment": {
                "risk_level": result.risk_level.value,
                "coefficient_of_variation": result.coefficient_of_variation,
                "risk_load": result.risk_load
            },
            "benchmarks": self._generate_industry_benchmarks(result.peril),
            "alerts": self._generate_alerts(result)
        }
        
        return dashboard
    
    def validate_sanity_checks(self, result: PricingResult) -> Dict[str, bool]:
        """
        ê°€ê²©ì±…ì • ê²°ê³¼ì˜ ê±´ì „ì„± ê²€ì¦
        
        Args:
            result: PricingResult ê°ì²´
            
        Returns:
            ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        
        checks = {}
        
        # 1. Tail Padding ê²€ì¦ (Risk Load â‰¥ 20% ë˜ëŠ” ELÃ—20%)
        checks["tail_padding"] = self.validate_tail_padding(result)
        
        # 2. ë³´í—˜ë£Œ í•©ë¦¬ì„± (ì´ ë³´í—˜ë£Œ > ìˆœ ë³´í—˜ë£Œ)
        checks["premium_consistency"] = result.gross_premium >= result.net_premium
        
        # 3. VaR/TVaR ê´€ê³„ (TVaR â‰¥ VaR)
        checks["var_tvar_consistency"] = result.tvar_99 >= result.var_99
        
        # 4. PML ë¹„ìœ¨ í•©ë¦¬ì„± (< 100x)
        checks["pml_ratio_reasonable"] = result.get_pml_ratio() < 100
        
        # 5. ë³€ë™ê³„ìˆ˜ í•©ë¦¬ì„± (< 5.0)
        checks["cov_reasonable"] = result.coefficient_of_variation < 5.0
        
        # 6. ê¸°ëŒ“ê°’ ì†ì‹¤ ì–‘ìˆ˜ í™•ì¸
        checks["positive_el"] = result.expected_loss >= 0
        
        # 7. Risk Load ë²”ìœ„ í™•ì¸ (0% ~ 200%)
        checks["risk_load_range"] = 0 <= result.risk_load <= 2.0
        
        return checks
    
    def validate_tail_padding(self, result: PricingResult) -> bool:
        """
        Tail Padding ê²€ì¦ (Risk Load â‰¥ 20% ë˜ëŠ” ELÃ—20% ì¶”ê°€)
        
        Args:
            result: PricingResult ê°ì²´
            
        Returns:
            Tail padding ì¡°ê±´ ë§Œì¡± ì—¬ë¶€
        """
        # modify_plan.md ìš”êµ¬ì‚¬í•­: RiskLoad â‰¥ 20% ë˜ëŠ” ELÃ—20% ì¶”ê°€
        min_risk_load = 0.20
        el_based_padding = result.expected_loss * 0.20
        
        return (result.risk_load >= min_risk_load) or \
               (result.gross_premium - result.net_premium >= el_based_padding)
    
    def _generate_industry_benchmarks(self, peril: str) -> Dict[str, float]:
        """ìœ„í—˜ íƒ€ì…ë³„ ì‚°ì—… ë²¤ì¹˜ë§ˆí¬"""
        
        benchmarks = {
            "typhoon": {
                "typical_el_range": [50000, 200000],
                "typical_cov_range": [0.4, 0.8],
                "typical_risk_load": 0.35,
                "market_premium_range": [0.15, 0.25]
            },
            "flight_delay": {
                "typical_el_range": [10000, 50000],
                "typical_cov_range": [0.3, 0.6],
                "typical_risk_load": 0.25,
                "market_premium_range": [0.10, 0.20]
            },
            "server_downtime": {
                "typical_el_range": [5000, 100000],
                "typical_cov_range": [0.5, 1.0],
                "typical_risk_load": 0.40,
                "market_premium_range": [0.20, 0.30]
            },
            "earthquake": {
                "typical_el_range": [20000, 500000],
                "typical_cov_range": [0.6, 1.2],
                "typical_risk_load": 0.50,
                "market_premium_range": [0.25, 0.40]
            }
        }
        
        return benchmarks.get(peril, {
            "typical_el_range": [10000, 100000],
            "typical_cov_range": [0.3, 0.8],
            "typical_risk_load": 0.30,
            "market_premium_range": [0.15, 0.25]
        })
    
    def _generate_alerts(self, result: PricingResult) -> List[str]:
        """ê°€ê²©ì±…ì • ê²°ê³¼ ê¸°ë°˜ ì•Œë¦¼ ìƒì„±"""
        
        alerts = []
        
        # ë†’ì€ ë³€ë™ì„± ê²½ê³ 
        if result.coefficient_of_variation > 1.0:
            alerts.append(f"âš ï¸ ë†’ì€ ë³€ë™ì„± (CoV: {result.coefficient_of_variation:.2f}) - í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì‚° í•„ìš”")
        
        # ë†’ì€ PML ë¹„ìœ¨ ê²½ê³ 
        pml_ratio = result.get_pml_ratio()
        if pml_ratio > 20:
            alerts.append(f"âš ï¸ ë†’ì€ PML ë¹„ìœ¨ ({pml_ratio:.1f}x) - ì¬ë³´í—˜ ê³ ë ¤ í•„ìš”")
        
        # ë‚®ì€ Risk Load ê²½ê³ 
        if result.risk_load < 0.15:
            alerts.append(f"âš ï¸ ë‚®ì€ Risk Load ({result.risk_load:.2f}) - Tail ë¦¬ìŠ¤í¬ ê³¼ì†Œí‰ê°€ ê°€ëŠ¥ì„±")
        
        # ë§¤ìš° ë†’ì€ ë¦¬ìŠ¤í¬ ë ˆë²¨ ê²½ê³ 
        if result.risk_level.value == "very_high":
            alerts.append("ğŸš¨ ë§¤ìš° ë†’ì€ ë¦¬ìŠ¤í¬ - ìƒí’ˆ ì¶œì‹œ ì¬ê²€í†  í•„ìš”")
        
        # ë¹„ì •ìƒì ì¸ ì§€í‘œ ê²½ê³ 
        if result.expected_loss <= 0:
            alerts.append("âŒ ê¸°ëŒ“ê°’ ì†ì‹¤ì´ 0 ë˜ëŠ” ìŒìˆ˜ - ëª¨ë¸ ê²€í†  í•„ìš”")
        
        return alerts
    
    def create_audit_trail(
        self,
        process_id: str,
        user_input: str,
        canvas: PerilCanvas,
        frequency_prior: FrequencyPrior,
        severity_prior: SeverityPrior,
        scenarios: pd.DataFrame,
        pricing_result: PricingResult,
        llm_conversations: List[Dict[str, str]] = None
    ) -> AuditTrail:
        """
        ê·œì œ ëŒ€ì‘ìš© ê°ì‚¬ ì¶”ì  ì •ë³´ ìƒì„±
        
        Args:
            process_id: í”„ë¡œì„¸ìŠ¤ ê³ ìœ  ID
            user_input: ì›ë³¸ ì‚¬ìš©ì ì…ë ¥
            canvas: ìƒì„±ëœ PerilCanvas
            frequency_prior: ë¹ˆë„ Prior
            severity_prior: ì‹¬ë„ Prior
            scenarios: ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„°
            pricing_result: ìµœì¢… ê°€ê²©ì±…ì • ê²°ê³¼
            llm_conversations: LLM ëŒ€í™” ê¸°ë¡
            
        Returns:
            AuditTrail ê°ì²´
        """
        
        # ì‹œë‚˜ë¦¬ì˜¤ ìš”ì•½ í†µê³„
        scenario_summary = {
            "total_scenarios": len(scenarios),
            "mean_annual_loss": float(scenarios["annual_loss"].mean()),
            "std_annual_loss": float(scenarios["annual_loss"].std()),
            "zero_loss_years": int((scenarios["annual_loss"] == 0).sum()),
            "max_annual_loss": float(scenarios["annual_loss"].max()),
            "total_events": int(scenarios["event_count"].sum()),
            "tail_scenarios": int(scenarios.get("tail_scenario", pd.Series()).notna().sum())
        }
        
        # ê²€ì¦ ì²´í¬ ì‹¤í–‰
        validation_checks = self.validate_sanity_checks(pricing_result)
        
        return AuditTrail(
            process_id=process_id,
            user_input=user_input,
            peril_canvas=canvas,
            frequency_prior=frequency_prior,
            severity_prior=severity_prior,
            llm_conversations=llm_conversations or [],
            scenario_summary=scenario_summary,
            pricing_result=pricing_result,
            validation_checks=validation_checks,
            created_at=datetime.now().isoformat()
        )
    
    def export_audit_trail(self, audit_trail: AuditTrail, filepath: str) -> str:
        """
        ê°ì‚¬ ì¶”ì  ì •ë³´ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            audit_trail: AuditTrail ê°ì²´
            filepath: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        
        # Pydantic ëª¨ë¸ì„ JSONìœ¼ë¡œ ì§ë ¬í™”
        audit_data = audit_trail.dict()
        
        # JSON íŒŒì¼ë¡œ ì €ì¥ (ê°€ë…ì„±ì„ ìœ„í•´ ë“¤ì—¬ì“°ê¸° ì ìš©)
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(audit_data, f, indent=2, ensure_ascii=False, default=str)
        
        return filepath
    
    def generate_executive_summary(
        self, 
        pricing_result: PricingResult,
        canvas: PerilCanvas,
        dashboard: Dict[str, any]
    ) -> str:
        """
        ê²½ì˜ì§„ ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
        
        Args:
            pricing_result: ê°€ê²©ì±…ì • ê²°ê³¼
            canvas: PerilCanvas
            dashboard: Sanity Dashboard
            
        Returns:
            ìš”ì•½ ë³´ê³ ì„œ í…ìŠ¤íŠ¸
        """
        
        summary = f"""
# {canvas.peril.upper()} íŒŒë¼ë©”íŠ¸ë¦­ ë³´í—˜ ê°€ê²©ì±…ì • ìš”ì•½

## ğŸ“Š í•µì‹¬ ì§€í‘œ
- **ê¸°ëŒ“ê°’ ì†ì‹¤**: ${pricing_result.expected_loss:,.0f}
- **ê¶Œì¥ ë³´í—˜ë£Œ**: ${pricing_result.gross_premium:,.0f}
- **ë¦¬ìŠ¤í¬ ë ˆë²¨**: {pricing_result.risk_level.value.upper()}
- **ë³€ë™ê³„ìˆ˜**: {pricing_result.coefficient_of_variation:.2f}

## ğŸ’¡ ì¶”ì²œì‚¬í•­
{pricing_result.recommendation}

## ğŸ¯ ìœ„í—˜ êµ¬ì¡°
- **íŠ¸ë¦¬ê±° ì¡°ê±´**: {canvas.limit_structure.trigger_condition.metric} {canvas.limit_structure.trigger_condition.operator} {canvas.limit_structure.trigger_condition.threshold} {canvas.limit_structure.trigger_condition.unit}
- **ìµœëŒ€ ì§€ê¸‰ì•¡**: ${canvas.limit_structure.payout_curve.max_payout:,.0f}
- **ì§€ê¸‰ ê³¡ì„ **: {canvas.limit_structure.payout_curve.curve_type.value}

## ğŸ“ˆ ë¦¬ìŠ¤í¬ ë¶„ì„
- **99% VaR**: ${pricing_result.var_99:,.0f}
- **99% TVaR**: ${pricing_result.tvar_99:,.0f}
- **PML ë¹„ìœ¨**: {pricing_result.get_pml_ratio():.1f}x

## âœ… ê²€ì¦ ìƒíƒœ
"""
        
        # ê²€ì¦ ê²°ê³¼ ì¶”ê°€
        validation = dashboard["validation_checks"]
        passed_checks = sum(validation.values())
        total_checks = len(validation)
        
        summary += f"- **ê²€ì¦ í†µê³¼ìœ¨**: {passed_checks}/{total_checks} ({passed_checks/total_checks*100:.0f}%)\n"
        
        if not all(validation.values()):
            summary += "\n## âš ï¸ ê²€ì¦ ì‹¤íŒ¨ í•­ëª©\n"
            for check, passed in validation.items():
                if not passed:
                    summary += f"- {check}: ì‹¤íŒ¨\n"
        
        # ì•Œë¦¼ ì¶”ê°€
        alerts = dashboard["alerts"]
        if alerts:
            summary += "\n## ğŸš¨ ì£¼ì˜ì‚¬í•­\n"
            for alert in alerts:
                summary += f"- {alert}\n"
        
        summary += f"\n---\nìƒì„±ì¼ì‹œ: {pricing_result.timestamp}\nì‹œë®¬ë ˆì´ì…˜: {pricing_result.simulation_years:,}ë…„"
        
        return summary
    
    def export_pricing_report(
        self,
        pricing_result: PricingResult,
        canvas: PerilCanvas,
        scenarios: pd.DataFrame,
        output_dir: str
    ) -> Dict[str, str]:
        """
        ì™„ì „í•œ ê°€ê²©ì±…ì • ë¦¬í¬íŠ¸ íŒ¨í‚¤ì§€ ìƒì„±
        
        Args:
            pricing_result: ê°€ê²©ì±…ì • ê²°ê³¼
            canvas: PerilCanvas
            scenarios: ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„°
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
            
        Returns:
            ìƒì„±ëœ íŒŒì¼ë“¤ì˜ ê²½ë¡œ ë”•ì…”ë„ˆë¦¬
        """
        
        import os
        from datetime import datetime
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(output_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        base_filename = f"{canvas.peril}_{timestamp}"
        
        files_created = {}
        
        # 1. ê°€ê²©ì±…ì • í…Œì´ë¸” (CSV)
        pricing_table = self.generate_pricing_table([pricing_result])
        table_path = os.path.join(output_dir, f"{base_filename}_pricing_table.csv")
        pricing_table.to_csv(table_path, index=False)
        files_created["pricing_table"] = table_path
        
        # 2. ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„° (CSV)
        scenario_path = os.path.join(output_dir, f"{base_filename}_scenarios.csv")
        # ì‹œë‚˜ë¦¬ì˜¤ í‰ë©´í™” ì €ì¥
        self._export_flattened_scenarios(scenarios, scenario_path)
        files_created["scenarios"] = scenario_path
        
        # 3. Sanity Dashboard (JSON)
        dashboard = self.generate_sanity_dashboard(pricing_result)
        dashboard_path = os.path.join(output_dir, f"{base_filename}_dashboard.json")
        with open(dashboard_path, 'w', encoding='utf-8') as f:
            json.dump(dashboard, f, indent=2, ensure_ascii=False, default=str)
        files_created["dashboard"] = dashboard_path
        
        # 4. ê²½ì˜ì§„ ìš”ì•½ (Markdown)
        executive_summary = self.generate_executive_summary(pricing_result, canvas, dashboard)
        summary_path = os.path.join(output_dir, f"{base_filename}_executive_summary.md")
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write(executive_summary)
        files_created["executive_summary"] = summary_path
        
        return files_created
    
    def _export_flattened_scenarios(self, scenarios: pd.DataFrame, filepath: str) -> None:
        """ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„°ë¥¼ í‰ë©´í™”í•˜ì—¬ CSVë¡œ ì €ì¥"""
        
        flattened_data = []
        
        for _, row in scenarios.iterrows():
            year = row["year"]
            event_count = row["event_count"]
            annual_loss = row["annual_loss"]
            events = row.get("events_with_payouts", [])
            tail_scenario = row.get("tail_scenario", None)
            
            if not events:
                # ì´ë²¤íŠ¸ê°€ ì—†ëŠ” ì—°ë„
                flattened_data.append({
                    "year": year,
                    "event_count": 0,
                    "annual_loss": 0.0,
                    "event_id": None,
                    "severity": None,
                    "payout": 0.0,
                    "triggered": False,
                    "tail_scenario": tail_scenario
                })
            else:
                # ê° ì´ë²¤íŠ¸ë³„ë¡œ í–‰ ìƒì„±
                for event in events:
                    flattened_data.append({
                        "year": year,
                        "event_count": event_count,
                        "annual_loss": annual_loss,
                        "event_id": event.get("event_id"),
                        "severity": event.get("severity"),
                        "payout": event.get("payout", 0.0),
                        "triggered": event.get("triggered", False),
                        "tail_scenario": tail_scenario
                    })
        
        df = pd.DataFrame(flattened_data)
        df.to_csv(filepath, index=False)


# í¸ì˜ í•¨ìˆ˜ë“¤
def generate_pricing_report(
    pricing_result: PricingResult,
    canvas: PerilCanvas,
    scenarios: pd.DataFrame
) -> Dict[str, any]:
    """ê°„í¸í•œ ê°€ê²©ì±…ì • ë¦¬í¬íŠ¸ ìƒì„±"""
    reporter = PricingReporter()
    
    dashboard = reporter.generate_sanity_dashboard(pricing_result)
    pricing_table = reporter.generate_pricing_table([pricing_result])
    executive_summary = reporter.generate_executive_summary(pricing_result, canvas, dashboard)
    
    return {
        "dashboard": dashboard,
        "pricing_table": pricing_table,
        "executive_summary": executive_summary,
        "validation_passed": all(dashboard["validation_checks"].values())
    }


def create_process_audit_trail(
    user_input: str,
    canvas: PerilCanvas,
    frequency_prior: FrequencyPrior,
    severity_prior: SeverityPrior,
    scenarios: pd.DataFrame,
    pricing_result: PricingResult
) -> AuditTrail:
    """ê°„í¸í•œ ê°ì‚¬ ì¶”ì  ìƒì„±"""
    reporter = PricingReporter()
    process_id = f"pricing_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}"
    
    return reporter.create_audit_trail(
        process_id, user_input, canvas, frequency_prior, severity_prior,
        scenarios, pricing_result
    )