"""
Prior Extraction System (STEP 1)

í™•ë¥ -ì£¼ë„ í”„ë¡¬í”„íŒ…ì„ í†µí•´ LLMì—ì„œ í™•ë¥  ë¶„í¬ ëª¨ìˆ˜ë¥¼ ì¶”ì¶œí•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.
ì‹¤ì¸¡ ë°ì´í„°ê°€ ì—†ëŠ” ìƒí™©ì—ì„œ LLMì˜ ì „ë¬¸ì§€ì‹ì„ í™œìš©í•˜ì—¬ Prior ë¶„í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import json
import asyncio
from typing import Dict, List, Optional, Tuple
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

from .models.base import (
    PerilCanvas, FrequencyPrior, SeverityPrior, DistributionType
)
from ..core.config import get_config
from .utils.prompt_templates import PriorExtractionPrompts


class PriorExtractor:
    """LLM ê¸°ë°˜ í™•ë¥  ë¶„í¬ ëª¨ìˆ˜ ì¶”ì¶œê¸°"""
    
    def __init__(self):
        self.config = get_config()
        self._llm = None
    
    @property
    def llm(self) -> ChatOpenAI:
        """ì§€ì—° ì´ˆê¸°í™”ëœ LLM ì¸ìŠ¤í„´ìŠ¤"""
        if self._llm is None:
            self._llm = ChatOpenAI(
                model=self.config.model_name,
                temperature=0.1,  # ì¼ê´€ì„±ì„ ìœ„í•´ ë§¤ìš° ë‚®ì€ temperature
                max_tokens=1500,
                api_key=self.config.openai_api_key
            )
        return self._llm
    
    async def extract_priors(self, canvas: PerilCanvas) -> Tuple[FrequencyPrior, SeverityPrior]:
        """
        Peril Canvasë¡œë¶€í„° ë¹ˆë„ ë° ì‹¬ë„ Prior ì¶”ì¶œ
        
        Args:
            canvas: ìƒì„±ëœ PerilCanvas ê°ì²´
            
        Returns:
            Tuple of (FrequencyPrior, SeverityPrior)
        """
        # ë™ì‹œì— ë¹ˆë„ì™€ ì‹¬ë„ Prior ì¶”ì¶œ
        frequency_task = self.extract_frequency_prior(
            canvas.peril, canvas.region, canvas.data_sources
        )
        severity_task = self.extract_severity_prior(
            canvas.peril, canvas.trigger_metric, 
            canvas.limit_structure.trigger_condition.unit
        )
        
        frequency_prior, severity_prior = await asyncio.gather(
            frequency_task, severity_task
        )
        
        # Self-Critique Loopìœ¼ë¡œ ì¼ê´€ì„± ê²€ì¦
        validated_priors = await self.self_critique_loop(
            canvas, frequency_prior, severity_prior
        )
        
        return validated_priors["frequency"], validated_priors["severity"]
    
    async def extract_frequency_prior(
        self, peril: str, region: str, data_sources: List[str]
    ) -> FrequencyPrior:
        """
        ì—°ê°„ ë°œìƒ ë¹ˆë„ Prior ì¶”ì¶œ (Negative-Binomial)
        
        Args:
            peril: ìœ„í—˜ íƒ€ì…
            region: ì ìš© ì§€ì—­
            data_sources: ë°ì´í„° ì†ŒìŠ¤ ëª©ë¡
            
        Returns:
            FrequencyPrior ê°ì²´
        """
        
        # ìƒˆë¡œìš´ ì•ˆì „í•œ í…œí”Œë¦¿ ì‹œìŠ¤í…œ ì‚¬ìš©
        prompt = PriorExtractionPrompts.get_frequency_prompt()
        
        try:
            print(f"ğŸ” [API] ë¹ˆë„ Prior LLM í˜¸ì¶œ ì¤‘... (ìœ„í—˜: {peril}, ì§€ì—­: {region})")
            print(f"ğŸ”§ [TEMPLATE] ì•ˆì „í•œ ChatPromptTemplate ì‚¬ìš©")
            
            messages = prompt.format_messages(
                peril=peril, 
                region=region, 
                data_sources=", ".join(data_sources) if data_sources else "Standard meteorological databases"
            )
            
            response = await self.llm.ainvoke(messages)
            print(f"âœ… [API] ë¹ˆë„ Prior LLM ì‘ë‹µ ì„±ê³µ")
            print(f"ğŸ” [API] ì‘ë‹µ ë‚´ìš©: {response.content[:300]}...")
            
            # ê°•í™”ëœ JSON íŒŒì‹± ë¡œì§ ì‚¬ìš©
            prior_data = self._parse_llm_json_response(response.content, "ë¹ˆë„ Prior")
            if prior_data:
                return FrequencyPrior(**prior_data)
            else:
                raise ValueError("JSON íŒŒì‹± ì‹¤íŒ¨")
            
        except (json.JSONDecodeError, Exception) as e:
            print(f"âŒ [API] ë¹ˆë„ Prior LLM í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
            # Fallback: ê¸°ë³¸ Prior ë°˜í™˜
            return self._get_default_frequency_prior(peril, region)
    
    async def extract_severity_prior(
        self, peril: str, metric: str, unit: str
    ) -> SeverityPrior:
        """
        ì´ë²¤íŠ¸ ì‹¬ë„ Prior ì¶”ì¶œ (LogNormal, Gamma ë“±)
        
        Args:
            peril: ìœ„í—˜ íƒ€ì…
            metric: íŠ¸ë¦¬ê±° ì§€í‘œ
            unit: ì¸¡ì • ë‹¨ìœ„
            
        Returns:
            SeverityPrior ê°ì²´
        """
        
        # ìœ„í—˜ íƒ€ì…ë³„ ì ì ˆí•œ ë¶„í¬ ì„ íƒ
        recommended_distribution = self._get_recommended_severity_distribution(peril, metric)
        
        # ìƒˆë¡œìš´ ì•ˆì „í•œ í…œí”Œë¦¿ ì‹œìŠ¤í…œ ì‚¬ìš©
        # í‹°ì¼“ ê´€ë ¨ ì§€í‘œì¸ì§€ í™•ì¸í•˜ì—¬ ì ì ˆí•œ í”„ë¡¬í”„íŠ¸ ì„ íƒ
        if "tickets" in metric or "ticket" in metric:
            prompt = PriorExtractionPrompts.get_severity_tickets_prompt(
                recommended_distribution, unit, metric
            )
            print(f"ğŸ”§ [TEMPLATE] í‹°ì¼“ íŠ¹í™” ChatPromptTemplate ì‚¬ìš©")
        else:
            prompt = PriorExtractionPrompts.get_severity_prompt(
                recommended_distribution, unit
            )
            print(f"ğŸ”§ [TEMPLATE] í‘œì¤€ ChatPromptTemplate ì‚¬ìš©")
        
        try:
            print(f"ğŸ” [API] ì‹¬ë„ Prior LLM í˜¸ì¶œ ì¤‘... (ìœ„í—˜: {peril}, ì§€í‘œ: {metric})")
            
            messages = prompt.format_messages(
                peril=peril,
                metric=metric,
                unit=unit,
                distribution=recommended_distribution
            )
            
            response = await self.llm.ainvoke(messages)
            print(f"âœ… [API] ì‹¬ë„ Prior LLM ì‘ë‹µ ì„±ê³µ")
            print(f"ğŸ” [API] ì‘ë‹µ ë‚´ìš©: {response.content[:300]}...")
            
            # ê°•í™”ëœ JSON íŒŒì‹± ë¡œì§ ì‚¬ìš©
            prior_data = self._parse_llm_json_response(response.content, "ì‹¬ë„ Prior")
            if prior_data:
                # LLM ì œê³µ íŒŒë¼ë¯¸í„°ì™€ percentileì´ ë¶ˆì¼ì¹˜í•  ê²½ìš° ìˆ˜ì •
                corrected_prior_data = self._correct_distribution_parameters(prior_data)
                return SeverityPrior(**corrected_prior_data)
            else:
                raise ValueError("JSON íŒŒì‹± ì‹¤íŒ¨")
            
        except (json.JSONDecodeError, Exception) as e:
            print(f"âŒ [API] ì‹¬ë„ Prior LLM í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
            # Fallback: ê¸°ë³¸ Prior ë°˜í™˜
            return self._get_default_severity_prior(peril, metric, unit)
    
    def _parse_llm_json_response(self, content: str, context: str) -> Optional[Dict]:
        """
        LLM ì‘ë‹µì—ì„œ JSONì„ ì•ˆì „í•˜ê²Œ íŒŒì‹±
        
        Args:
            content: LLM ì‘ë‹µ ë‚´ìš©
            context: ë¡œê¹…ì„ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ (ì˜ˆ: "ë¹ˆë„ Prior", "ì‹¬ë„ Prior")
            
        Returns:
            íŒŒì‹±ëœ JSON ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None
        """
        try:
            # ê¸°ë³¸ ì •ë¦¬
            content = content.strip()
            
            # ì½”ë“œ ë¸”ë¡ ì œê±°
            if content.startswith("```json"):
                content = content[7:]
            elif content.startswith("```"):
                content = content[3:]
            if content.endswith("```"):
                content = content[:-3]
            
            content = content.strip()
            
            # ì´ì¤‘ ì¤‘ê´„í˜¸ ì²˜ë¦¬ - LangChain í…œí”Œë¦¿ì—ì„œ ì´ìŠ¤ì¼€ì´í”„ëœ ê²ƒì„ ì›ë˜ëŒ€ë¡œ
            content = content.replace('{{', '{').replace('}}', '}')
            
            # JSON ì¶”ì¶œ - ì²« ë²ˆì§¸ { ë¶€í„° ë§ˆì§€ë§‰ } ê¹Œì§€
            start_idx = content.find('{')
            end_idx = content.rfind('}')
            
            if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
                json_content = content[start_idx:end_idx+1]
                print(f"ğŸ” [API] {context} JSON ì¶”ì¶œ: {json_content}")
                
                # JSON íŒŒì‹± ì‹œë„
                result = json.loads(json_content)
                print(f"âœ… [API] {context} JSON íŒŒì‹± ì„±ê³µ: {result}")
                return result
            else:
                print(f"âŒ [API] {context} JSON êµ¬ì¡°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return None
                
        except json.JSONDecodeError as e:
            print(f"âŒ [API] {context} JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
            print(f"ğŸ” [API] íŒŒì‹± ì‹¤íŒ¨ ë‚´ìš©: {content[:500]}...")
            return None
        except Exception as e:
            print(f"âŒ [API] {context} ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def _get_recommended_severity_distribution(self, peril: str, metric: str) -> str:
        """ìœ„í—˜ íƒ€ì…ê³¼ ì§€í‘œì— ë”°ë¥¸ ê¶Œì¥ ë¶„í¬"""
        
        distribution_mapping = {
            ("typhoon", "central_pressure"): "lognormal",
            ("typhoon", "wind_speed"): "gamma",
            ("concert_cancellation", "event_intensity"): "gamma",
            ("concert_cancellation", "cancellation_rate"): "gamma",  # ìƒˆë¡œìš´ ì§€í‘œ ì¶”ê°€
            ("event_cancellation", "event_intensity"): "gamma",
            ("flight_delay", "delay_minutes"): "gamma",
            ("earthquake", "magnitude"): "gamma",
            ("server_downtime", "downtime_minutes"): "exponential",
            ("flood", "water_level"): "lognormal",
            ("drought", "precipitation_deficit"): "gamma"
        }
        
        return distribution_mapping.get((peril, metric), "lognormal")
    
    def _correct_distribution_parameters(self, prior_data: dict) -> dict:
        """LLMì´ ì œê³µí•œ ë¶„í¬ íŒŒë¼ë¯¸í„°ë¥¼ percentile ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì •"""
        
        distribution = prior_data.get("distribution", "lognormal")
        percentiles = prior_data.get("percentiles", {})
        parameters = prior_data.get("parameters", {})
        
        # percentile ê°’ì´ ì—†ìœ¼ë©´ ì›ë³¸ ë°˜í™˜
        if not percentiles or "50th" not in percentiles:
            return prior_data
        
        try:
            p50 = float(percentiles["50th"])
            
            if distribution == "lognormal":
                # LogNormal ë¶„í¬ íŒŒë¼ë¯¸í„° ìˆ˜ì •
                corrected_params = self._correct_lognormal_parameters(percentiles, parameters)
                if corrected_params:
                    print(f"ğŸ”§ [PRIOR] LogNormal íŒŒë¼ë¯¸í„° ìˆ˜ì •: {parameters} â†’ {corrected_params}")
                    prior_data["parameters"] = corrected_params
            
            elif distribution == "gamma":
                # Gamma ë¶„í¬ íŒŒë¼ë¯¸í„° ìˆ˜ì •
                corrected_params = self._correct_gamma_parameters(percentiles, parameters)
                if corrected_params:
                    print(f"ğŸ”§ [PRIOR] Gamma íŒŒë¼ë¯¸í„° ìˆ˜ì •: {parameters} â†’ {corrected_params}")
                    prior_data["parameters"] = corrected_params
            
            return prior_data
            
        except (ValueError, TypeError) as e:
            print(f"âš ï¸ [PRIOR] ë¶„í¬ íŒŒë¼ë¯¸í„° ìˆ˜ì • ì‹¤íŒ¨: {e} - ì›ë³¸ ì‚¬ìš©")
            return prior_data
    
    def _correct_lognormal_parameters(self, percentiles: dict, original_params: dict) -> dict:
        """LogNormal ë¶„í¬ íŒŒë¼ë¯¸í„°ë¥¼ percentile ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì •"""
        
        try:
            import numpy as np
            
            p50 = float(percentiles["50th"])
            
            # 50th percentile = exp(mu)ì´ë¯€ë¡œ mu ê³„ì‚°
            mu = np.log(p50)
            
            # 95th percentileì´ ìˆìœ¼ë©´ sigma ê³„ì‚°
            if "95th" in percentiles:
                p95 = float(percentiles["95th"])
                # P95 / P50 = exp(1.645 * sigma)
                ratio = p95 / p50
                sigma = np.log(ratio) / 1.645
            else:
                # ê¸°ë³¸ê°’ ì‚¬ìš©
                sigma = original_params.get("sigma", 0.5)
            
            # í•©ë¦¬ì ì¸ ë²”ìœ„ë¡œ ì œí•œ
            mu = max(-2, min(15, mu))  # exp(-2) â‰ˆ 0.14, exp(15) â‰ˆ 3.3M
            sigma = max(0.1, min(2.0, sigma))  # ë„ˆë¬´ ì¢ê±°ë‚˜ ë„“ì§€ ì•Šê²Œ
            
            return {"mu": round(mu, 3), "sigma": round(sigma, 3)}
            
        except Exception as e:
            print(f"âš ï¸ [PRIOR] LogNormal íŒŒë¼ë¯¸í„° ìˆ˜ì • ì‹¤íŒ¨: {e}")
            return None
    
    def _correct_gamma_parameters(self, percentiles: dict, original_params: dict) -> dict:
        """Gamma ë¶„í¬ íŒŒë¼ë¯¸í„°ë¥¼ percentile ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì •"""
        
        try:
            import numpy as np
            from scipy import stats, optimize
            
            p50 = float(percentiles["50th"])
            
            # ê¸°ì¡´ íŒŒë¼ë¯¸í„°ê°€ ìˆìœ¼ë©´ ë³´ì •, ì—†ìœ¼ë©´ ì¶”ì •
            if "alpha" in original_params and "beta" in original_params:
                alpha = float(original_params["alpha"])
                beta = float(original_params["beta"])
                
                # ìŠ¤ì¼€ì¼ ì¡°ì • (mean = alpha/beta = p50ì˜ ì•½ 80% ì •ë„)
                target_mean = p50 * 0.8
                scale_factor = target_mean / (alpha / beta)
                beta = beta * scale_factor
                
            else:
                # ê¸°ë³¸ê°’ìœ¼ë¡œ ì¶”ì • (shape=2, scaleì€ p50 ê¸°ì¤€)
                alpha = 2.0
                beta = alpha / (p50 * 0.8)
            
            # í•©ë¦¬ì ì¸ ë²”ìœ„ë¡œ ì œí•œ
            alpha = max(0.5, min(10.0, alpha))
            beta = max(0.001, min(100.0, beta))
            
            return {"alpha": round(alpha, 3), "beta": round(beta, 3)}
            
        except Exception as e:
            print(f"âš ï¸ [PRIOR] Gamma íŒŒë¼ë¯¸í„° ìˆ˜ì • ì‹¤íŒ¨: {e}")
            return None
    
    async def self_critique_loop(
        self, canvas: PerilCanvas, frequency_prior: FrequencyPrior, severity_prior: SeverityPrior
    ) -> Dict[str, any]:
        """
        LLM Self-Critique Loopìœ¼ë¡œ ëª¨ìˆ˜ ì¼ê´€ì„± ê²€ì¦ ë° ìˆ˜ì •
        
        Args:
            canvas: PerilCanvas ê°ì²´
            frequency_prior: ì¶”ì¶œëœ ë¹ˆë„ Prior
            severity_prior: ì¶”ì¶œëœ ì‹¬ë„ Prior
            
        Returns:
            ê²€ì¦ ë° ìˆ˜ì •ëœ Prior ë”•ì…”ë„ˆë¦¬
        """
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """
You are a senior actuarial reviewer. Examine the consistency and reasonableness of these parametric insurance model parameters.

Response format (JSON only):
{
    "consistent": true/false,
    "issues": ["Issue 1", "Issue 2"],
    "corrections": {
        "frequency": {
            "parameters": {"r": 2.8, "p": 0.8},
            "rationale": "Adjustment reason"
        },
        "severity": {
            "parameters": {"mu": 2.0, "sigma": 0.5},
            "rationale": "Adjustment reason"
        }
    },
    "overall_assessment": "Brief assessment of model credibility"
}

Consistency checks:
1. Parameter ranges within realistic bounds
2. Frequency-severity relationship makes sense
3. Regional applicability of parameters
4. Historical precedent alignment
5. Extreme scenario plausibility
"""),
            ("human", """
Event: {peril} in {region}
Trigger: {metric} {unit}

Frequency Prior (Negative-Binomial):
- r = {freq_r}, p = {freq_p}
- 50th percentile: {freq_50th} events/year

Severity Prior ({severity_dist}):
- Î¼ = {sev_mu}, Ïƒ = {sev_sigma}
- 50th percentile: {sev_50th} {unit}

Are these parameters self-consistent and realistic? If not, provide corrections.
""")
        ])
        
        try:
            messages = prompt.format_messages(
                peril=canvas.peril,
                region=canvas.region,
                metric=canvas.trigger_metric,
                unit=canvas.limit_structure.trigger_condition.unit,
                freq_r=frequency_prior.parameters.get("r"),
                freq_p=frequency_prior.parameters.get("p"),
                freq_50th=frequency_prior.percentiles.get("50th"),
                severity_dist=severity_prior.distribution,
                sev_mu=severity_prior.parameters.get("mu", "N/A"),
                sev_sigma=severity_prior.parameters.get("sigma", "N/A"),
                sev_50th=severity_prior.percentiles.get("50th")
            )
            response = await self.llm.ainvoke(messages)
            
            critique_result = json.loads(response.content)
            
            # ìˆ˜ì •ì‚¬í•­ì´ ìˆë‹¤ë©´ ì ìš©
            if not critique_result["consistent"] and "corrections" in critique_result:
                corrected_frequency = self._apply_frequency_corrections(
                    frequency_prior, critique_result["corrections"].get("frequency")
                )
                corrected_severity = self._apply_severity_corrections(
                    severity_prior, critique_result["corrections"].get("severity")
                )
                
                return {
                    "frequency": corrected_frequency,
                    "severity": corrected_severity,
                    "critique": critique_result
                }
            
            return {
                "frequency": frequency_prior,
                "severity": severity_prior,
                "critique": critique_result
            }
            
        except (json.JSONDecodeError, Exception) as e:
            # Fallback: ì›ë³¸ Prior ë°˜í™˜
            return {
                "frequency": frequency_prior,
                "severity": severity_prior,
                "critique": {"consistent": True, "issues": [], "overall_assessment": "Default validation"}
            }
    
    def _apply_frequency_corrections(self, original: FrequencyPrior, corrections: Optional[Dict]) -> FrequencyPrior:
        """ë¹ˆë„ Prior ìˆ˜ì •ì‚¬í•­ ì ìš©"""
        if not corrections or "parameters" not in corrections:
            return original
        
        # ìƒˆë¡œìš´ íŒŒë¼ë¯¸í„°ë¡œ ì—…ë°ì´íŠ¸
        updated_params = {**original.parameters, **corrections["parameters"]}
        
        return FrequencyPrior(
            distribution=original.distribution,
            parameters=updated_params,
            percentiles=original.percentiles,  # ë°±ë¶„ìœ„ìˆ˜ëŠ” ì¬ê³„ì‚° í•„ìš”í•˜ì§€ë§Œ ì¼ë‹¨ ìœ ì§€
            sources=original.sources,
            confidence=original.confidence * 0.9  # ìˆ˜ì •ìœ¼ë¡œ ì¸í•œ ì‹ ë¢°ë„ ì•½ê°„ ê°ì†Œ
        )
    
    def _apply_severity_corrections(self, original: SeverityPrior, corrections: Optional[Dict]) -> SeverityPrior:
        """ì‹¬ë„ Prior ìˆ˜ì •ì‚¬í•­ ì ìš©"""
        if not corrections or "parameters" not in corrections:
            return original
        
        # ìƒˆë¡œìš´ íŒŒë¼ë¯¸í„°ë¡œ ì—…ë°ì´íŠ¸
        updated_params = {**original.parameters, **corrections["parameters"]}
        
        return SeverityPrior(
            distribution=original.distribution,
            parameters=updated_params,
            percentiles=original.percentiles,
            metric_unit=original.metric_unit,
            sources=original.sources,
            confidence=original.confidence * 0.9
        )
    
    def _get_default_frequency_prior(self, peril: str, region: str) -> FrequencyPrior:
        """ê¸°ë³¸ ë¹ˆë„ Prior (LLM ì‹¤íŒ¨ ì‹œ)"""
        
        default_priors = {
            "typhoon": {
                "parameters": {"r": 2.5, "p": 0.8},
                "percentiles": {"5th": 0.0, "50th": 1.0, "95th": 4.0},
                "sources": ["JMA Historical Database", "NOAA Storm Database"]
            },
            "concert_cancellation": {
                "parameters": {"r": 3.0, "p": 0.85},
                "percentiles": {"5th": 0.0, "50th": 1.0, "95th": 3.0},
                "sources": ["Entertainment Industry Reports", "Event Management Statistics"]
            },
            "event_cancellation": {
                "parameters": {"r": 4.0, "p": 0.8},
                "percentiles": {"5th": 0.0, "50th": 2.0, "95th": 5.0},
                "sources": ["Event Industry Database", "Insurance Claims Data"]
            },
            "flight_delay": {
                "parameters": {"r": 5.0, "p": 0.7},
                "percentiles": {"5th": 1.0, "50th": 3.0, "95th": 8.0},
                "sources": ["FlightAware Statistics", "OAG Performance Data"]
            },
            "earthquake": {
                "parameters": {"r": 1.5, "p": 0.9},
                "percentiles": {"5th": 0.0, "50th": 0.0, "95th": 2.0},
                "sources": ["USGS Earthquake Database", "Regional Seismic Networks"]
            },
            "server_downtime": {
                "parameters": {"r": 8.0, "p": 0.6},
                "percentiles": {"5th": 2.0, "50th": 5.0, "95th": 12.0},
                "sources": ["Industry Uptime Statistics", "Cloud Provider SLAs"]
            }
        }
        
        default = default_priors.get(peril, {
            "parameters": {"r": 3.0, "p": 0.75},
            "percentiles": {"5th": 0.0, "50th": 1.0, "95th": 5.0},
            "sources": ["Industry Statistics", "Expert Judgment"]
        })
        
        return FrequencyPrior(
            distribution=DistributionType.NEGATIVE_BINOMIAL,
            parameters=default["parameters"],
            percentiles=default["percentiles"],
            sources=default["sources"],
            confidence=0.7  # ê¸°ë³¸ê°’ì€ ë‚®ì€ ì‹ ë¢°ë„
        )
    
    def _get_default_severity_prior(self, peril: str, metric: str, unit: str) -> SeverityPrior:
        """ê¸°ë³¸ ì‹¬ë„ Prior (LLM ì‹¤íŒ¨ ì‹œ)"""
        
        default_priors = {
            ("typhoon", "central_pressure"): {
                "distribution": DistributionType.LOGNORMAL,
                "parameters": {"mu": 2.1, "sigma": 0.6},
                "percentiles": {"5th": 3.2, "50th": 8.1, "95th": 25.4},
                "sources": ["JMA Storm Database"]
            },
            ("concert_cancellation", "event_intensity"): {
                "distribution": DistributionType.GAMMA,
                "parameters": {"alpha": 1.5, "beta": 0.5},
                "percentiles": {"5th": 0.2, "50th": 2.5, "95th": 8.0},
                "sources": ["Entertainment Industry Reports"]
            },
            ("event_cancellation", "event_intensity"): {
                "distribution": DistributionType.GAMMA,
                "parameters": {"alpha": 2.0, "beta": 0.4},
                "percentiles": {"5th": 0.5, "50th": 4.0, "95th": 12.0},
                "sources": ["Event Management Statistics"]
            },
            ("flight_delay", "delay_minutes"): {
                "distribution": DistributionType.GAMMA,
                "parameters": {"alpha": 2.0, "beta": 0.03},
                "percentiles": {"5th": 15.0, "50th": 67.0, "95th": 180.0},
                "sources": ["Aviation Statistics"]
            },
            ("server_downtime", "downtime_minutes"): {
                "distribution": DistributionType.EXPONENTIAL,
                "parameters": {"lambda": 0.1},
                "percentiles": {"5th": 0.5, "50th": 6.9, "95th": 30.0},
                "sources": ["IT Industry Reports"]
            }
        }
        
        key = (peril, metric)
        default = default_priors.get(key, {
            "distribution": DistributionType.LOGNORMAL,
            "parameters": {"mu": 1.0, "sigma": 0.5},
            "percentiles": {"5th": 1.2, "50th": 2.7, "95th": 7.4},
            "sources": ["Expert Judgment"]
        })
        
        return SeverityPrior(
            distribution=default["distribution"],
            parameters=default["parameters"],
            percentiles=default["percentiles"],
            metric_unit=unit,
            sources=default["sources"],
            confidence=0.7
        )


# í¸ì˜ í•¨ìˆ˜ë“¤
async def extract_priors_from_canvas(canvas: PerilCanvas) -> Tuple[FrequencyPrior, SeverityPrior]:
    """ê°„í¸í•œ Prior ì¶”ì¶œ í•¨ìˆ˜"""
    extractor = PriorExtractor()
    return await extractor.extract_priors(canvas)


async def validate_prior_consistency(
    frequency_prior: FrequencyPrior, 
    severity_prior: SeverityPrior,
    canvas: PerilCanvas
) -> Dict[str, any]:
    """ê°„í¸í•œ Prior ì¼ê´€ì„± ê²€ì¦ í•¨ìˆ˜"""
    extractor = PriorExtractor()
    result = await extractor.self_critique_loop(canvas, frequency_prior, severity_prior)
    return result["critique"]